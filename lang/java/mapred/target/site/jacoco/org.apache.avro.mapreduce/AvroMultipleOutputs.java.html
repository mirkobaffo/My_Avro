<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AvroMultipleOutputs.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache Avro Mapred API</a> &gt; <a href="index.source.html" class="el_package">org.apache.avro.mapreduce</a> &gt; <span class="el_source">AvroMultipleOutputs.java</span></div><h1>AvroMultipleOutputs.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.avro.mapreduce;

import java.io.IOException;
import java.lang.reflect.Constructor;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.StringTokenizer;

import org.apache.avro.Schema;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.JobContext;
import org.apache.hadoop.mapreduce.OutputFormat;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.TaskAttemptID;
import org.apache.hadoop.mapreduce.TaskInputOutputContext;
import org.apache.hadoop.util.ReflectionUtils;

/**
 * The AvroMultipleOutputs class simplifies writing Avro output data to multiple
 * outputs
 *
 * &lt;p&gt;
 * Case one: writing to additional outputs other than the job default output.
 *
 * Each additional output, or named output, may be configured with its own
 * &lt;code&gt;Schema&lt;/code&gt; and &lt;code&gt;OutputFormat&lt;/code&gt;.
 * &lt;/p&gt;
 * &lt;p&gt;
 * Case two: to write data to different files provided by user
 * &lt;/p&gt;
 *
 * &lt;p&gt;
 * AvroMultipleOutputs supports counters, by default they are disabled. The
 * counters group is the {@link AvroMultipleOutputs} class name. The names of
 * the counters are the same as the output name. These count the number of
 * records written to each output name.
 * &lt;/p&gt;
 *
 * Usage pattern for job submission:
 * 
 * &lt;pre&gt;
 *
 * Job job = Job.getInstance();
 *
 * FileInputFormat.setInputPath(job, inDir);
 * FileOutputFormat.setOutputPath(job, outDir);
 *
 * job.setMapperClass(MyAvroMapper.class);
 * job.setReducerClass(MyAvroReducer.class);
 * ...
 *
 * Schema schema;
 * ...
 * // Defines additional single output 'avro1' for the job
 * AvroMultipleOutputs.addNamedOutput(job, &quot;avro1&quot;, AvroKeyValueOutputFormat.class,
 * keyschema, valueSchema);  // valueSchema can be set to null if there only Key to be written
                                   to file in the RecordWriter
 *
 * // Defines additional output 'avro2' with different schema for the job
 * AvroMultipleOutputs.addNamedOutput(job, &quot;avro2&quot;,
 *   AvroKeyOutputFormat.class,
 *   schema,null);
 * ...
 *
 * job.waitForCompletion(true);
 * ...
 * &lt;/pre&gt;
 * &lt;p&gt;
 * Usage in Reducer:
 * 
 * &lt;pre&gt;
 *
 * public class MyAvroReducer extends
 *   Reducer&amp;lt;K, V, T, NullWritable&amp;gt; {
 * private MultipleOutputs amos;
 *
 *
 * public void setup(Context context) {
 * ...
 * amos = new AvroMultipleOutputs(context);
 * }
 *
 * public void reduce(K, Iterator&amp;lt;V&amp;gt; values,Context context)
 * throws IOException {
 * ...
 * amos.write(&quot;avro1&quot;,datum,NullWritable.get());
 * amos.write(&quot;avro2&quot;,datum,NullWritable.get());
 * amos.getCollector(&quot;avro3&quot;,datum); // here the value is taken as NullWritable
 * ...
 * }
 *
 * public void cleanup(Context context) throws IOException {
 * amos.close();
 * ...
 * }
 *
 * }
 * &lt;/pre&gt;
 */

public class AvroMultipleOutputs {

  private static final String MULTIPLE_OUTPUTS = &quot;avro.mapreduce.multipleoutputs&quot;;

  private static final String MO_PREFIX = &quot;avro.mapreduce.multipleoutputs.namedOutput.&quot;;

  private static final String FORMAT = &quot;.format&quot;;
  private static final String COUNTERS_ENABLED = &quot;avro.mapreduce.multipleoutputs.counters&quot;;

  /**
   * Counters group used by the counters of MultipleOutputs.
   */
<span class="nc" id="L138">  private static final String COUNTERS_GROUP = AvroMultipleOutputs.class.getName();</span>

  /**
   * Cache for the taskContexts
   */
<span class="nc" id="L143">  private Map&lt;String, TaskAttemptContext&gt; taskContexts = new HashMap&lt;&gt;();</span>

  /**
   * Checks if a named output name is valid token.
   *
   * @param namedOutput named output Name
   * @throws IllegalArgumentException if the output name is not valid.
   */
  private static void checkTokenName(String namedOutput) {
<span class="nc bnc" id="L152" title="All 4 branches missed.">    if (namedOutput == null || namedOutput.length() == 0) {</span>
<span class="nc" id="L153">      throw new IllegalArgumentException(&quot;Name cannot be NULL or empty&quot;);</span>
    }
<span class="nc bnc" id="L155" title="All 2 branches missed.">    for (char ch : namedOutput.toCharArray()) {</span>
<span class="nc bnc" id="L156" title="All 4 branches missed.">      if ((ch &gt;= 'A') &amp;&amp; (ch &lt;= 'Z')) {</span>
<span class="nc" id="L157">        continue;</span>
      }
<span class="nc bnc" id="L159" title="All 4 branches missed.">      if ((ch &gt;= 'a') &amp;&amp; (ch &lt;= 'z')) {</span>
<span class="nc" id="L160">        continue;</span>
      }
<span class="nc bnc" id="L162" title="All 4 branches missed.">      if ((ch &gt;= '0') &amp;&amp; (ch &lt;= '9')) {</span>
<span class="nc" id="L163">        continue;</span>
      }
<span class="nc" id="L165">      throw new IllegalArgumentException(&quot;Name cannot have a '&quot; + ch + &quot;' char&quot;);</span>
    }
<span class="nc" id="L167">  }</span>

  /**
   * Checks if output name is valid.
   *
   * name cannot be the name used for the default output
   * 
   * @param outputPath base output Name
   * @throws IllegalArgumentException if the output name is not valid.
   */
  private static void checkBaseOutputPath(String outputPath) {
<span class="nc bnc" id="L178" title="All 2 branches missed.">    if (outputPath.equals(&quot;part&quot;)) {</span>
<span class="nc" id="L179">      throw new IllegalArgumentException(&quot;output name cannot be 'part'&quot;);</span>
    }
<span class="nc" id="L181">  }</span>

  /**
   * Checks if a named output name is valid.
   *
   * @param namedOutput named output Name
   * @throws IllegalArgumentException if the output name is not valid.
   */
  private static void checkNamedOutputName(JobContext job, String namedOutput, boolean alreadyDefined) {
<span class="nc" id="L190">    checkTokenName(namedOutput);</span>
<span class="nc" id="L191">    checkBaseOutputPath(namedOutput);</span>
<span class="nc" id="L192">    List&lt;String&gt; definedChannels = getNamedOutputsList(job);</span>
<span class="nc bnc" id="L193" title="All 4 branches missed.">    if (alreadyDefined &amp;&amp; definedChannels.contains(namedOutput)) {</span>
<span class="nc" id="L194">      throw new IllegalArgumentException(&quot;Named output '&quot; + namedOutput + &quot;' already alreadyDefined&quot;);</span>
<span class="nc bnc" id="L195" title="All 4 branches missed.">    } else if (!alreadyDefined &amp;&amp; !definedChannels.contains(namedOutput)) {</span>
<span class="nc" id="L196">      throw new IllegalArgumentException(&quot;Named output '&quot; + namedOutput + &quot;' not defined&quot;);</span>
    }
<span class="nc" id="L198">  }</span>

  // Returns list of channel names.
  private static List&lt;String&gt; getNamedOutputsList(JobContext job) {
<span class="nc" id="L202">    List&lt;String&gt; names = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L203">    StringTokenizer st = new StringTokenizer(job.getConfiguration().get(MULTIPLE_OUTPUTS, &quot;&quot;), &quot; &quot;);</span>
<span class="nc bnc" id="L204" title="All 2 branches missed.">    while (st.hasMoreTokens()) {</span>
<span class="nc" id="L205">      names.add(st.nextToken());</span>
    }
<span class="nc" id="L207">    return names;</span>
  }

  // Returns the named output OutputFormat.
  @SuppressWarnings(&quot;unchecked&quot;)
  private static Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt; getNamedOutputFormatClass(JobContext job, String namedOutput) {
<span class="nc" id="L213">    return (Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;) job.getConfiguration().getClass(MO_PREFIX + namedOutput + FORMAT, null,</span>
        OutputFormat.class);
  }

  /**
   * Adds a named output for the job.
   * &lt;p/&gt;
   *
   * @param job               job to add the named output
   * @param namedOutput       named output name, it has to be a word, letters and
   *                          numbers only, cannot be the word 'part' as that is
   *                          reserved for the default output.
   * @param outputFormatClass OutputFormat class.
   * @param keySchema         Schema for the Key
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public static void addNamedOutput(Job job, String namedOutput, Class&lt;? extends OutputFormat&gt; outputFormatClass,
      Schema keySchema) {
<span class="nc" id="L231">    addNamedOutput(job, namedOutput, outputFormatClass, keySchema, null);</span>
<span class="nc" id="L232">  }</span>

  /**
   * Adds a named output for the job.
   * &lt;p/&gt;
   *
   * @param job               job to add the named output
   * @param namedOutput       named output name, it has to be a word, letters and
   *                          numbers only, cannot be the word 'part' as that is
   *                          reserved for the default output.
   * @param outputFormatClass OutputFormat class.
   * @param keySchema         Schema for the Key
   * @param valueSchema       Schema for the Value (used in case of
   *                          AvroKeyValueOutputFormat or null)
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public static void addNamedOutput(Job job, String namedOutput, Class&lt;? extends OutputFormat&gt; outputFormatClass,
      Schema keySchema, Schema valueSchema) {
<span class="nc" id="L250">    checkNamedOutputName(job, namedOutput, true);</span>
<span class="nc" id="L251">    Configuration conf = job.getConfiguration();</span>
<span class="nc" id="L252">    conf.set(MULTIPLE_OUTPUTS, conf.get(MULTIPLE_OUTPUTS, &quot;&quot;) + &quot; &quot; + namedOutput);</span>
<span class="nc" id="L253">    conf.setClass(MO_PREFIX + namedOutput + FORMAT, outputFormatClass, OutputFormat.class);</span>
<span class="nc" id="L254">    conf.set(MO_PREFIX + namedOutput + &quot;.keyschema&quot;, keySchema.toString());</span>
<span class="nc bnc" id="L255" title="All 2 branches missed.">    if (valueSchema != null) {</span>
<span class="nc" id="L256">      conf.set(MO_PREFIX + namedOutput + &quot;.valueschema&quot;, valueSchema.toString());</span>
    }
<span class="nc" id="L258">  }</span>

  /**
   * Enables or disables counters for the named outputs.
   *
   * The counters group is the {@link AvroMultipleOutputs} class name. The names
   * of the counters are the same as the named outputs. These counters count the
   * number records written to each output name. By default these counters are
   * disabled.
   *
   * @param job     job to enable counters
   * @param enabled indicates if the counters will be enabled or not.
   */
  public static void setCountersEnabled(Job job, boolean enabled) {
<span class="nc" id="L272">    job.getConfiguration().setBoolean(COUNTERS_ENABLED, enabled);</span>
<span class="nc" id="L273">  }</span>

  /**
   * Returns if the counters for the named outputs are enabled or not. By default
   * these counters are disabled.
   *
   * @param job the job
   * @return TRUE if the counters are enabled, FALSE if they are disabled.
   */
  public static boolean getCountersEnabled(JobContext job) {
<span class="nc" id="L283">    return job.getConfiguration().getBoolean(COUNTERS_ENABLED, false);</span>
  }

  /**
   * Wraps RecordWriter to increment counters.
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  private static class RecordWriterWithCounter extends RecordWriter {
    private RecordWriter writer;
    private String counterName;
    private TaskInputOutputContext context;

<span class="nc" id="L295">    public RecordWriterWithCounter(RecordWriter writer, String counterName, TaskInputOutputContext context) {</span>
<span class="nc" id="L296">      this.writer = writer;</span>
<span class="nc" id="L297">      this.counterName = counterName;</span>
<span class="nc" id="L298">      this.context = context;</span>
<span class="nc" id="L299">    }</span>

    @SuppressWarnings({ &quot;unchecked&quot; })
    @Override
    public void write(Object key, Object value) throws IOException, InterruptedException {
<span class="nc" id="L304">      context.getCounter(COUNTERS_GROUP, counterName).increment(1);</span>
<span class="nc" id="L305">      writer.write(key, value);</span>
<span class="nc" id="L306">    }</span>

    @Override
    public void close(TaskAttemptContext context) throws IOException, InterruptedException {
<span class="nc" id="L310">      writer.close(context);</span>
<span class="nc" id="L311">    }</span>
  }

  // instance code, to be used from Mapper/Reducer code

  private TaskInputOutputContext&lt;?, ?, ?, ?&gt; context;
  private Set&lt;String&gt; namedOutputs;
  private Map&lt;String, RecordWriter&lt;?, ?&gt;&gt; recordWriters;
  private boolean countersEnabled;

  /**
   * Creates and initializes multiple outputs support, it should be instantiated
   * in the Mapper/Reducer setup method.
   *
   * @param context the TaskInputOutputContext object
   */
<span class="nc" id="L327">  public AvroMultipleOutputs(TaskInputOutputContext&lt;?, ?, ?, ?&gt; context) {</span>
<span class="nc" id="L328">    this.context = context;</span>
<span class="nc" id="L329">    namedOutputs = Collections.unmodifiableSet(new HashSet&lt;&gt;(AvroMultipleOutputs.getNamedOutputsList(context)));</span>
<span class="nc" id="L330">    recordWriters = new HashMap&lt;&gt;();</span>
<span class="nc" id="L331">    countersEnabled = getCountersEnabled(context);</span>
<span class="nc" id="L332">  }</span>

  /**
   * Write key and value to the namedOutput.
   *
   * Output path is a unique file generated for the namedOutput. For example,
   * {namedOutput}-(m|r)-{part-number}
   *
   * @param namedOutput the named output name
   * @param key         the key , value is NullWritable
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public void write(String namedOutput, Object key) throws IOException, InterruptedException {
<span class="nc" id="L345">    write(namedOutput, key, NullWritable.get(), namedOutput);</span>
<span class="nc" id="L346">  }</span>

  /**
   * Write key and value to the namedOutput.
   *
   * Output path is a unique file generated for the namedOutput. For example,
   * {namedOutput}-(m|r)-{part-number}
   *
   * @param namedOutput the named output name
   * @param key         the key
   * @param value       the value
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public void write(String namedOutput, Object key, Object value) throws IOException, InterruptedException {
<span class="nc" id="L360">    write(namedOutput, key, value, namedOutput);</span>
<span class="nc" id="L361">  }</span>

  /**
   * Write key and value to baseOutputPath using the namedOutput.
   *
   * @param namedOutput    the named output name
   * @param key            the key
   * @param value          the value
   * @param baseOutputPath base-output path to write the record to. Note:
   *                       Framework will generate unique filename for the
   *                       baseOutputPath
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public void write(String namedOutput, Object key, Object value, String baseOutputPath)
      throws IOException, InterruptedException {
<span class="nc" id="L376">    checkNamedOutputName(context, namedOutput, false);</span>
<span class="nc" id="L377">    checkBaseOutputPath(baseOutputPath);</span>
<span class="nc bnc" id="L378" title="All 2 branches missed.">    if (!namedOutputs.contains(namedOutput)) {</span>
<span class="nc" id="L379">      throw new IllegalArgumentException(&quot;Undefined named output '&quot; + namedOutput + &quot;'&quot;);</span>
    }
<span class="nc" id="L381">    TaskAttemptContext taskContext = getContext(namedOutput);</span>
<span class="nc" id="L382">    getRecordWriter(taskContext, baseOutputPath).write(key, value);</span>
<span class="nc" id="L383">  }</span>

  /**
   * Write key value to an output file name.
   *
   * Gets the record writer from job's output format. Job's output format should
   * be a FileOutputFormat.
   *
   * @param key            the key
   * @param value          the value
   * @param baseOutputPath base-output path to write the record to. Note:
   *                       Framework will generate unique filename for the
   *                       baseOutputPath
   */
  public void write(Object key, Object value, String baseOutputPath) throws IOException, InterruptedException {
<span class="nc" id="L398">    write(key, value, null, null, baseOutputPath);</span>
<span class="nc" id="L399">  }</span>

  /**
   * Write key value to an output file name.
   *
   * Gets the record writer from job's output format. Job's output format should
   * be a FileOutputFormat.
   *
   * @param key            the key
   * @param value          the value
   * @param keySchema      keySchema to use
   * @param valSchema      ValueSchema to use
   * @param baseOutputPath base-output path to write the record to. Note:
   *                       Framework will generate unique filename for the
   *                       baseOutputPath
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public void write(Object key, Object value, Schema keySchema, Schema valSchema, String baseOutputPath)
      throws IOException, InterruptedException {
<span class="nc" id="L418">    checkBaseOutputPath(baseOutputPath);</span>
<span class="nc" id="L419">    Job job = Job.getInstance(context.getConfiguration());</span>
<span class="nc" id="L420">    setSchema(job, keySchema, valSchema);</span>
<span class="nc" id="L421">    TaskAttemptContext taskContext = createTaskAttemptContext(job.getConfiguration(), context.getTaskAttemptID());</span>
<span class="nc" id="L422">    getRecordWriter(taskContext, baseOutputPath).write(key, value);</span>
<span class="nc" id="L423">  }</span>

  /**
   *
   * Gets the record writer from job's output format. Job's output format should
   * be a FileOutputFormat.If the record writer implements Syncable then returns
   * the current position as a value that may be passed to
   * DataFileReader.seek(long) otherwise returns -1. Forces the end of the current
   * block, emitting a synchronization marker.
   *
   * @param namedOutput    the namedOutput
   * @param baseOutputPath base-output path to write the record to. Note:
   *                       Framework will generate unique filename for the
   *                       baseOutputPath
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public long sync(String namedOutput, String baseOutputPath) throws IOException, InterruptedException {
<span class="nc" id="L440">    checkNamedOutputName(context, namedOutput, false);</span>
<span class="nc" id="L441">    checkBaseOutputPath(baseOutputPath);</span>
<span class="nc bnc" id="L442" title="All 2 branches missed.">    if (!namedOutputs.contains(namedOutput)) {</span>
<span class="nc" id="L443">      throw new IllegalArgumentException(&quot;Undefined named output '&quot; + namedOutput + &quot;'&quot;);</span>
    }
<span class="nc" id="L445">    TaskAttemptContext taskContext = getContext(namedOutput);</span>
<span class="nc" id="L446">    RecordWriter recordWriter = getRecordWriter(taskContext, baseOutputPath);</span>
<span class="nc" id="L447">    long position = -1;</span>
<span class="nc bnc" id="L448" title="All 2 branches missed.">    if (recordWriter instanceof Syncable) {</span>
<span class="nc" id="L449">      Syncable syncableWriter = (Syncable) recordWriter;</span>
<span class="nc" id="L450">      position = syncableWriter.sync();</span>
    }
<span class="nc" id="L452">    return position;</span>
  }

  // by being synchronized MultipleOutputTask can be use with a
  // MultithreadedMapper.
  @SuppressWarnings(&quot;unchecked&quot;)
  private synchronized RecordWriter getRecordWriter(TaskAttemptContext taskContext, String baseFileName)
      throws IOException, InterruptedException {

    // look for record-writer in the cache
<span class="nc" id="L462">    RecordWriter writer = recordWriters.get(baseFileName);</span>

    // If not in cache, create a new one
<span class="nc bnc" id="L465" title="All 2 branches missed.">    if (writer == null) {</span>
      // get the record writer from context output format
      // FileOutputFormat.setOutputName(taskContext, baseFileName);
<span class="nc" id="L468">      taskContext.getConfiguration().set(&quot;avro.mo.config.namedOutput&quot;, baseFileName);</span>
      try {
<span class="nc" id="L470">        writer = ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), taskContext.getConfiguration())</span>
<span class="nc" id="L471">            .getRecordWriter(taskContext);</span>
<span class="nc" id="L472">      } catch (ClassNotFoundException e) {</span>
<span class="nc" id="L473">        throw new IOException(e);</span>
<span class="nc" id="L474">      }</span>

      // if counters are enabled, wrap the writer with context
      // to increment counters
<span class="nc bnc" id="L478" title="All 2 branches missed.">      if (countersEnabled) {</span>
<span class="nc" id="L479">        writer = new RecordWriterWithCounter(writer, baseFileName, context);</span>
      }

      // add the record-writer to the cache
<span class="nc" id="L483">      recordWriters.put(baseFileName, writer);</span>
    }
<span class="nc" id="L485">    return writer;</span>
  }

  private void setSchema(Job job, Schema keySchema, Schema valSchema) {

<span class="nc bnc" id="L490" title="All 2 branches missed.">    boolean isMaponly = job.getNumReduceTasks() == 0;</span>
<span class="nc bnc" id="L491" title="All 2 branches missed.">    if (keySchema != null) {</span>
<span class="nc bnc" id="L492" title="All 2 branches missed.">      if (isMaponly)</span>
<span class="nc" id="L493">        AvroJob.setMapOutputKeySchema(job, keySchema);</span>
      else
<span class="nc" id="L495">        AvroJob.setOutputKeySchema(job, keySchema);</span>
    }
<span class="nc bnc" id="L497" title="All 2 branches missed.">    if (valSchema != null) {</span>
<span class="nc bnc" id="L498" title="All 2 branches missed.">      if (isMaponly)</span>
<span class="nc" id="L499">        AvroJob.setMapOutputValueSchema(job, valSchema);</span>
      else
<span class="nc" id="L501">        AvroJob.setOutputValueSchema(job, valSchema);</span>
    }

<span class="nc" id="L504">  }</span>

  // Create a taskAttemptContext for the named output with
  // output format and output key/value types put in the context
  @SuppressWarnings(&quot;deprecation&quot;)
  private TaskAttemptContext getContext(String nameOutput) throws IOException {

<span class="nc" id="L511">    TaskAttemptContext taskContext = taskContexts.get(nameOutput);</span>

<span class="nc bnc" id="L513" title="All 2 branches missed.">    if (taskContext != null) {</span>
<span class="nc" id="L514">      return taskContext;</span>
    }

    // The following trick leverages the instantiation of a record writer via
    // the job thus supporting arbitrary output formats.
<span class="nc" id="L519">    Job job = new Job(context.getConfiguration());</span>
<span class="nc" id="L520">    job.setOutputFormatClass(getNamedOutputFormatClass(context, nameOutput));</span>
<span class="nc" id="L521">    Schema keySchema = null, valSchema = null;</span>
<span class="nc bnc" id="L522" title="All 2 branches missed.">    if (job.getConfiguration().get(MO_PREFIX + nameOutput + &quot;.keyschema&quot;, null) != null)</span>
<span class="nc" id="L523">      keySchema = Schema.parse(job.getConfiguration().get(MO_PREFIX + nameOutput + &quot;.keyschema&quot;));</span>
<span class="nc bnc" id="L524" title="All 2 branches missed.">    if (job.getConfiguration().get(MO_PREFIX + nameOutput + &quot;.valueschema&quot;, null) != null)</span>
<span class="nc" id="L525">      valSchema = Schema.parse(job.getConfiguration().get(MO_PREFIX + nameOutput + &quot;.valueschema&quot;));</span>
<span class="nc" id="L526">    setSchema(job, keySchema, valSchema);</span>
<span class="nc" id="L527">    taskContext = createTaskAttemptContext(job.getConfiguration(), context.getTaskAttemptID());</span>

<span class="nc" id="L529">    taskContexts.put(nameOutput, taskContext);</span>

<span class="nc" id="L531">    return taskContext;</span>
  }

  private TaskAttemptContext createTaskAttemptContext(Configuration conf, TaskAttemptID taskId) {
    // Use reflection since the context types changed incompatibly between 1.0
    // and 2.0.
    try {
<span class="nc" id="L538">      Class&lt;?&gt; c = getTaskAttemptContextClass();</span>
<span class="nc" id="L539">      Constructor&lt;?&gt; cons = c.getConstructor(Configuration.class, TaskAttemptID.class);</span>
<span class="nc" id="L540">      return (TaskAttemptContext) cons.newInstance(conf, taskId);</span>
<span class="nc" id="L541">    } catch (Exception e) {</span>
<span class="nc" id="L542">      throw new IllegalStateException(e);</span>
    }
  }

  private Class&lt;?&gt; getTaskAttemptContextClass() {
    try {
<span class="nc" id="L548">      return Class.forName(&quot;org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl&quot;);</span>
<span class="nc" id="L549">    } catch (Exception e) {</span>
      try {
<span class="nc" id="L551">        return Class.forName(&quot;org.apache.hadoop.mapreduce.TaskAttemptContext&quot;);</span>
<span class="nc" id="L552">      } catch (Exception ex) {</span>
<span class="nc" id="L553">        throw new IllegalStateException(ex);</span>
      }
    }
  }

  /**
   * Closes all the opened outputs.
   *
   * This should be called from cleanup method of map/reduce task. If overridden
   * subclasses must invoke &lt;code&gt;super.close()&lt;/code&gt; at the end of their
   * &lt;code&gt;close()&lt;/code&gt;
   *
   */
  @SuppressWarnings(&quot;unchecked&quot;)
  public void close() throws IOException, InterruptedException {
<span class="nc bnc" id="L568" title="All 2 branches missed.">    for (RecordWriter writer : recordWriters.values()) {</span>
<span class="nc" id="L569">      writer.close(context);</span>
<span class="nc" id="L570">    }</span>
<span class="nc" id="L571">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>