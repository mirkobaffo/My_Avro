<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AvroRecordReaderBase.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache Avro Mapred API</a> &gt; <a href="index.source.html" class="el_package">org.apache.avro.mapreduce</a> &gt; <span class="el_source">AvroRecordReaderBase.java</span></div><h1>AvroRecordReaderBase.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 * implied.  See the License for the specific language governing
 * permissions and limitations under the License.
 */

package org.apache.avro.mapreduce;

import java.io.IOException;

import org.apache.avro.Schema;
import org.apache.avro.file.DataFileReader;
import org.apache.avro.file.SeekableInput;
import org.apache.avro.generic.GenericData;
import org.apache.avro.hadoop.io.AvroSerialization;
import org.apache.avro.io.DatumReader;
import org.apache.avro.mapred.FsInput;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Abstract base class for &lt;code&gt;RecordReader&lt;/code&gt;s that read Avro container
 * files.
 *
 * @param &lt;K&gt; The type of key the record reader should generate.
 * @param &lt;V&gt; The type of value the record reader should generate.
 * @param &lt;T&gt; The type of the entries within the Avro container file being read.
 */
<span class="nc bnc" id="L47" title="All 2 branches missed.">public abstract class AvroRecordReaderBase&lt;K, V, T&gt; extends RecordReader&lt;K, V&gt; {</span>
<span class="nc" id="L48">  private static final Logger LOG = LoggerFactory.getLogger(AvroRecordReaderBase.class);</span>

  /** The reader schema for the records within the input Avro container file. */
  private final Schema mReaderSchema;

  /** The current record from the Avro container file being read. */
  private T mCurrentRecord;

  /** A reader for the Avro container file containing the current input split. */
  private DataFileReader&lt;T&gt; mAvroFileReader;

  /**
   * The byte offset into the Avro container file where the first block that fits
   * completely within the current input split begins.
   */
  private long mStartPosition;

  /**
   * The byte offset into the Avro container file where the current input split
   * ends.
   */
  private long mEndPosition;

  /**
   * Constructor.
   *
   * @param readerSchema The reader schema for the records of the Avro container
   *                     file.
   */
<span class="nc" id="L77">  protected AvroRecordReaderBase(Schema readerSchema) {</span>
<span class="nc" id="L78">    mReaderSchema = readerSchema;</span>
<span class="nc" id="L79">    mCurrentRecord = null;</span>
<span class="nc" id="L80">  }</span>

  /** {@inheritDoc} */
  @Override
  public void initialize(InputSplit inputSplit, TaskAttemptContext context) throws IOException, InterruptedException {
<span class="nc bnc" id="L85" title="All 2 branches missed.">    if (!(inputSplit instanceof FileSplit)) {</span>
<span class="nc" id="L86">      throw new IllegalArgumentException(&quot;Only compatible with FileSplits.&quot;);</span>
    }
<span class="nc" id="L88">    FileSplit fileSplit = (FileSplit) inputSplit;</span>

    // Open a seekable input stream to the Avro container file.
<span class="nc" id="L91">    SeekableInput seekableFileInput = createSeekableInput(context.getConfiguration(), fileSplit.getPath());</span>

    // Wrap the seekable input stream in an Avro DataFileReader.
<span class="nc" id="L94">    Configuration conf = context.getConfiguration();</span>
<span class="nc" id="L95">    GenericData dataModel = AvroSerialization.createDataModel(conf);</span>
<span class="nc" id="L96">    DatumReader&lt;T&gt; datumReader = dataModel.createDatumReader(mReaderSchema);</span>
<span class="nc" id="L97">    mAvroFileReader = createAvroFileReader(seekableFileInput, datumReader);</span>

    // Initialize the start and end offsets into the file based on the boundaries of
    // the
    // input split we're responsible for. We will read the first block that begins
    // after the input split start boundary. We will read up to but not including
    // the
    // first block that starts after input split end boundary.

    // Sync to the closest block/record boundary just after beginning of our input
    // split.
<span class="nc" id="L108">    mAvroFileReader.sync(fileSplit.getStart());</span>

    // Initialize the start position to the beginning of the first block of the
    // input split.
<span class="nc" id="L112">    mStartPosition = mAvroFileReader.previousSync();</span>

    // Initialize the end position to the end of the input split (this isn't
    // necessarily
    // on a block boundary so using this for reporting progress will be approximate.
<span class="nc" id="L117">    mEndPosition = fileSplit.getStart() + fileSplit.getLength();</span>
<span class="nc" id="L118">  }</span>

  /** {@inheritDoc} */
  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
<span class="nc bnc" id="L123" title="All 4 branches missed.">    assert null != mAvroFileReader;</span>

<span class="nc bnc" id="L125" title="All 4 branches missed.">    if (mAvroFileReader.hasNext() &amp;&amp; !mAvroFileReader.pastSync(mEndPosition)) {</span>
<span class="nc" id="L126">      mCurrentRecord = mAvroFileReader.next(mCurrentRecord);</span>
<span class="nc" id="L127">      return true;</span>
    }
<span class="nc" id="L129">    return false;</span>
  }

  /** {@inheritDoc} */
  @Override
  public float getProgress() throws IOException, InterruptedException {
<span class="nc bnc" id="L135" title="All 4 branches missed.">    assert null != mAvroFileReader;</span>

<span class="nc bnc" id="L137" title="All 2 branches missed.">    if (mEndPosition == mStartPosition) {</span>
      // Trivial empty input split.
<span class="nc" id="L139">      return 0.0f;</span>
    }
<span class="nc" id="L141">    long bytesRead = mAvroFileReader.previousSync() - mStartPosition;</span>
<span class="nc" id="L142">    long bytesTotal = mEndPosition - mStartPosition;</span>
<span class="nc" id="L143">    LOG.debug(&quot;Progress: bytesRead=&quot; + bytesRead + &quot;, bytesTotal=&quot; + bytesTotal);</span>
<span class="nc" id="L144">    return Math.min(1.0f, (float) bytesRead / (float) bytesTotal);</span>
  }

  /** {@inheritDoc} */
  @Override
  public void close() throws IOException {
<span class="nc bnc" id="L150" title="All 2 branches missed.">    if (null != mAvroFileReader) {</span>
      try {
<span class="nc" id="L152">        mAvroFileReader.close();</span>
      } finally {
<span class="nc" id="L154">        mAvroFileReader = null;</span>
      }
    }
<span class="nc" id="L157">  }</span>

  /**
   * Gets the current record read from the Avro container file.
   *
   * &lt;p&gt;
   * Calling &lt;code&gt;nextKeyValue()&lt;/code&gt; moves this to the next record.
   * &lt;/p&gt;
   *
   * @return The current Avro record (may be null if no record has been read).
   */
  protected T getCurrentRecord() {
<span class="nc" id="L169">    return mCurrentRecord;</span>
  }

  /**
   * Creates a seekable input stream to an Avro container file.
   *
   * @param conf The hadoop configuration.
   * @param path The path to the avro container file.
   * @throws IOException If there is an error reading from the path.
   */
  protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException {
<span class="nc" id="L180">    return new FsInput(path, conf);</span>
  }

  /**
   * Creates an Avro container file reader from a seekable input stream.
   *
   * @param input       The input containing the Avro container file.
   * @param datumReader The reader to use for the individual records in the Avro
   *                    container file.
   * @throws IOException If there is an error reading from the input stream.
   */
  protected DataFileReader&lt;T&gt; createAvroFileReader(SeekableInput input, DatumReader&lt;T&gt; datumReader) throws IOException {
<span class="nc" id="L192">    return new DataFileReader&lt;&gt;(input, datumReader);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>